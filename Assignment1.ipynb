{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vld16018/Assignment1/blob/master/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkwXnw9OfHZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxQ5RTSvo3o0",
        "colab_type": "code",
        "outputId": "b6423736-dffd-4542-dc0b-18687d53bef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/AI/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs0QzkMXBAMo",
        "colab_type": "code",
        "outputId": "7e4c8f18-734c-4cd2-9ef3-2aa7e522bb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = root_path + \"/Dataset.zip\"\n",
        "#file_name = \"Image_2.zip\"\n",
        "with ZipFile(file_name ,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print (\"Done\")\n",
        "#!rm -rf \"Dataset.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH8fq3BzikIx",
        "colab_type": "text"
      },
      "source": [
        "4 categories from 4 classes of train dataset as seen after folder extraction\n",
        "The train categories will be used for traing and validation with 80% for training  and  20% for validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J68uoavECPRO",
        "colab_type": "text"
      },
      "source": [
        "Creating a datagen class to convert them into train and test \n",
        "Normalise the data\n",
        "By default the image gets converted to 254*254 from 800*800\n",
        "As its  a black and white image using gray scale for analysing the data\n",
        "3 channel only required if data is present in them "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozR6Z6hTCqau",
        "colab_type": "code",
        "outputId": "82e7e93b-57cc-414f-dd2b-a5cd360208fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "# create a data generator\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0,featurewise_center=True, featurewise_std_normalization=True,rotation_range=90,width_shift_range=0.1, height_shift_range=0.1,horizontal_flip=True)\n",
        "#Cannot do fit for dataset\n",
        "train_set = datagen.flow_from_directory('Dataset/train/', class_mode='categorical', color_mode = \"grayscale\",batch_size=5)\n",
        "\n",
        "# load and iterate validation dataset\n",
        "#test_set = datagen.flow_from_directory('Dataset/test/',target_size=(200, 200),class_mode='categorical', color_mode = \"grayscale\",batch_size=1)\n",
        "test_set = datagen.flow_from_directory('Dataset/test/',class_mode='categorical', color_mode = \"grayscale\",batch_size=1)\n",
        "\n",
        "\n",
        "print('Batches train=%d, test=%d' % (len(train_set), len(test_set)))\n",
        "# confirm the scaling works\n",
        "batchX, batchy = train_set.next()\n",
        "print('Batch shape=%s, mean=%.3f min=%.3f, max=%.3f' % (batchX.shape, batchX.mean(),batchX.min(), batchX.max()))\n",
        "print('Batch shape=%s, mean=%.3f min=%.3f, max=%.3f' % (batchy.shape, batchX.mean(),batchX.min(), batchX.max()))\n",
        "print (batchy)\n",
        "image = batchX[4,:,:,:]\n",
        "print(image.shape)\n",
        "a = np.expand_dims(image, axis=0)  # or axis=1\n",
        "plt.imshow(image[:,:,0],cmap = 'gray')\n",
        "plt.show()\n",
        "#plt.imshow(batchX[0,:,:,:],cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 440 images belonging to 4 classes.\n",
            "Found 30 images belonging to 4 classes.\n",
            "Batches train=88, test=30\n",
            "Batch shape=(5, 256, 256, 1), mean=0.605 min=0.000, max=1.000\n",
            "Batch shape=(5, 4), mean=0.605 min=0.000, max=1.000\n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]]\n",
            "(256, 256, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lopzKh6q7rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJMT4rjgfdZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITXAtS0mgbhG",
        "colab_type": "text"
      },
      "source": [
        "Validation accuracy received is 0.8211 for the previous model for 100 epoch's\n",
        "\n",
        "\n",
        "1.   Model sequential with bottleneck layer after 3 conv layers and then max pooling is applied\n",
        "2.   Batch Norm & Dropout for regularisation \n",
        "3.   Adding l2 regularisation, tuned different values for max accuarcy  \n",
        "4.   Adding dropout increases to 0.7575 with 0.01  for 40 epoch\n",
        "5   Making architectural changes to existing architecture gives 86% to 90% in  20 epoch's\n",
        "6.  Architectural changes are with respect to receptive field. Each conv layer comment   contains layer output and receptive field calculation\n",
        "7.   Using 3*3 for reducing parameters in convolution layer\n",
        "8.   Getting an accuracy of 20% for SGD then shiifted to Adam\n",
        "9.  Cross_entropy was giving the above mentioned accuracy but when added bacth norm i the last layer it increased it to 86%. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSOb2lkJfhVq",
        "colab_type": "code",
        "outputId": "c10e6bde-69a5-4ea5-ae26-16e70b75a2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3,activation='relu',input_shape=(256, 256, 1),kernel_regularizer=regularizers.l2(0.0001))) #256,3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #254 #5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #252 #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "#7\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  #126 #14\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "#126 #14\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #124 #16\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #122 #18\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #120 #20\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1)) #20\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#60 #40 actually ask regarding these #200\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "#200 40\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #58 #42\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #56 #44\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #54 #46\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1)) #42\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#27 #92 actually ask regarding these 100\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #25 #94\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #23 #96\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #21 #98\n",
        "model.add(BatchNormalization()) #98\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11 #196 actually ask regarding these 50\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(4, 10,10,activation='relu',kernel_regularizer=regularizers.l2(0.0001))) #4 #206\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.1))\n",
        "# Compile model\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "epochs = 10\n",
        "learning_rate = 0.09\n",
        "decay_rate = learning_rate / epochs\n",
        "momentum = 0.5\n",
        "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(256, 256,..., kernel_regularizer=<keras.reg...)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (10, 10), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvVs5tC8mR6Q",
        "colab_type": "code",
        "outputId": "85776dc3-e4d7-4e12-a926-b9b91875e500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_170 (Conv2D)          (None, 254, 254, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_158 (Bat (None, 254, 254, 64)      256       \n",
            "_________________________________________________________________\n",
            "dropout_210 (Dropout)        (None, 254, 254, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_171 (Conv2D)          (None, 252, 252, 128)     73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_159 (Bat (None, 252, 252, 128)     512       \n",
            "_________________________________________________________________\n",
            "dropout_211 (Dropout)        (None, 252, 252, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_172 (Conv2D)          (None, 250, 250, 256)     295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_160 (Bat (None, 250, 250, 256)     1024      \n",
            "_________________________________________________________________\n",
            "dropout_212 (Dropout)        (None, 250, 250, 256)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 125, 125, 256)     0         \n",
            "_________________________________________________________________\n",
            "dropout_213 (Dropout)        (None, 125, 125, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_173 (Conv2D)          (None, 123, 123, 32)      73760     \n",
            "_________________________________________________________________\n",
            "batch_normalization_161 (Bat (None, 123, 123, 32)      128       \n",
            "_________________________________________________________________\n",
            "dropout_214 (Dropout)        (None, 123, 123, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_174 (Conv2D)          (None, 121, 121, 64)      18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_162 (Bat (None, 121, 121, 64)      256       \n",
            "_________________________________________________________________\n",
            "dropout_215 (Dropout)        (None, 121, 121, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_175 (Conv2D)          (None, 119, 119, 128)     73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_163 (Bat (None, 119, 119, 128)     512       \n",
            "_________________________________________________________________\n",
            "dropout_216 (Dropout)        (None, 119, 119, 128)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 59, 59, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_217 (Dropout)        (None, 59, 59, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_176 (Conv2D)          (None, 57, 57, 32)        36896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_164 (Bat (None, 57, 57, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_218 (Dropout)        (None, 57, 57, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_177 (Conv2D)          (None, 55, 55, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_165 (Bat (None, 55, 55, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_219 (Dropout)        (None, 55, 55, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_178 (Conv2D)          (None, 53, 53, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_166 (Bat (None, 53, 53, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_220 (Dropout)        (None, 53, 53, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_221 (Dropout)        (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_179 (Conv2D)          (None, 24, 24, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_167 (Bat (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_222 (Dropout)        (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_180 (Conv2D)          (None, 22, 22, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_168 (Bat (None, 22, 22, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_223 (Dropout)        (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_181 (Conv2D)          (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_169 (Bat (None, 20, 20, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_224 (Dropout)        (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_225 (Dropout)        (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_182 (Conv2D)          (None, 1, 1, 4)           25604     \n",
            "_________________________________________________________________\n",
            "batch_normalization_170 (Bat (None, 1, 1, 4)           16        \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 842,644\n",
            "Trainable params: 840,460\n",
            "Non-trainable params: 2,184\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oK_V7WyfsXX",
        "colab_type": "code",
        "outputId": "d1c7d5e0-25e8-4880-915f-4f1fe2ab8a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.0001 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "#datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                            # horizontal_flip=False)\n",
        "\n",
        "\n",
        "# train the model\n",
        "start = time.time()\n",
        "# Train the model\n",
        "#model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
        "#                                 samples_per_epoch = train_features.shape[0], nb_epoch = 100,validation_data=(X_test_iterator),validation_steps=len(X_test_iterator),\n",
        "#                                  verbose=1)\n",
        "\n",
        "#model_info = model.fit_generator(X_train_iterator, steps_per_epoch=len(X_train_iterator), epochs=80, verbose=1, validation_data=(X_test_iterator),validation_steps=len(X_test_iterator),callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "#model_info = model.fit_generator(train_set, steps_per_epoch=88, epochs=10, verbose=1, validation_data=(test_set),validation_steps=30,callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "model_info = model.fit_generator(train_set, steps_per_epoch=70, epochs=20, verbose=1, validation_data=(train_set),validation_steps=18,callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "\n",
        "#model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)\n",
        "end = time.time()\n",
        "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
        "_, acc = model.evaluate_generator(test_set, steps=len(test_set), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))\n",
        "# plot model history\n",
        "#plot_model_history(model_info)\n",
        "# compute test accuracy\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.0001.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "70/70 [==============================] - 23s 322ms/step - loss: 0.5377 - acc: 0.8686 - val_loss: 0.6819 - val_acc: 0.8000\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 7.5815e-05.\n",
            "70/70 [==============================] - 23s 323ms/step - loss: 0.5579 - acc: 0.8571 - val_loss: 0.6266 - val_acc: 0.8889\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 6.10501e-05.\n",
            "70/70 [==============================] - 22s 321ms/step - loss: 0.5939 - acc: 0.8200 - val_loss: 0.7352 - val_acc: 0.8444\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 5.10986e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5271 - acc: 0.8629 - val_loss: 0.5780 - val_acc: 0.9222\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 4.39367e-05.\n",
            "70/70 [==============================] - 22s 319ms/step - loss: 0.5861 - acc: 0.8257 - val_loss: 0.6950 - val_acc: 0.8556\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 3.85356e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5807 - acc: 0.8486 - val_loss: 0.6172 - val_acc: 0.8889\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 3.43171e-05.\n",
            "70/70 [==============================] - 22s 321ms/step - loss: 0.6253 - acc: 0.8429 - val_loss: 0.5904 - val_acc: 0.9000\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 3.0931e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5241 - acc: 0.8914 - val_loss: 0.5322 - val_acc: 0.9222\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 2.81532e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5841 - acc: 0.8486 - val_loss: 0.5418 - val_acc: 0.9000\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 2.58331e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5866 - acc: 0.8686 - val_loss: 0.5549 - val_acc: 0.9444\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 2.38663e-05.\n",
            "70/70 [==============================] - 22s 321ms/step - loss: 0.5856 - acc: 0.8486 - val_loss: 0.5609 - val_acc: 0.9222\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 2.21779e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5515 - acc: 0.8743 - val_loss: 0.5821 - val_acc: 0.8889\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 2.07125e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5466 - acc: 0.8571 - val_loss: 0.5594 - val_acc: 0.9000\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 1.94288e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.6058 - acc: 0.8371 - val_loss: 0.5840 - val_acc: 0.9111\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 1.82949e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5874 - acc: 0.8457 - val_loss: 0.5481 - val_acc: 0.9222\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 1.72861e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5492 - acc: 0.8600 - val_loss: 0.5655 - val_acc: 0.9111\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 1.63827e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5411 - acc: 0.8571 - val_loss: 0.6132 - val_acc: 0.9111\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 1.5569e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.4969 - acc: 0.8914 - val_loss: 0.5707 - val_acc: 0.9000\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 1.48324e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5062 - acc: 0.8943 - val_loss: 0.5628 - val_acc: 0.9222\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 1.41623e-05.\n",
            "70/70 [==============================] - 22s 320ms/step - loss: 0.5433 - acc: 0.8800 - val_loss: 0.5799 - val_acc: 0.8889\n",
            "Model took 448.80 seconds to train\n",
            "Test Accuracy: 96.667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5ZlRssx8Pil",
        "colab_type": "code",
        "outputId": "6c82dec9-d870-4a7c-8d99-00872e191f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ERAVnpA9yI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "_, acc = model.evaluate_generator(test_set, steps=len(test_set), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}